 1 лабораторна робота, звіт
Варіант 2

Скалярне множення векторів. Порівняти при різних вхідних даних та різній кількості потоків. 
Візьмемо наступні дані: 4, 8, 16 потоків; 10m, 20m вимірів векторів

Код:

'use strict';

const threads = require('worker_threads');
const { Worker } = threads;

const THREADS_COUNT_TESTS = [4, 8, 16];
const VECTOR_LENGTH_TESTS = [10000000, 20000000];
const MIN_VALUE = -100;
const MAX_VALUE = 100;

const scalarProduct = (vectorA, vectorB) =>
  vectorA.reduce((summ, curr, index) => summ + curr * vectorB[index], 0);

const newVector = length =>
  new Array(length)
    .fill(0)
    .map(() => Math.round(Math.random() * (MAX_VALUE - MIN_VALUE) + MIN_VALUE));

if (threads.isMainThread) {
  const f = async () => {
    const tests = {
      units: [],

      [Symbol.asyncIterator]() {
        let currUnit = 0;
        return {
          next() {
            if (currUnit === tests.units.length) return { done: true };
            let { threadsCount, vectorLength } = tests.units[currUnit++];

            const vector1 = newVector(vectorLength);
            const vector2 = newVector(vectorLength);

            console.log(`${threadsCount} threads\n${vectorLength} length\n`);

            const sequentialStart = new Date().getTime();
            const sequentialResult = scalarProduct(vector1, vector2);
            const sequentialTime = new Date().getTime() - sequentialStart;

            const resultsBuffer = new SharedArrayBuffer(threadsCount * 4);
            const results = new Int32Array(resultsBuffer);

            const workers = [];

            const oneThreadPart = Math.ceil(vectorLength / threadsCount);

            for (let workerNumb = 0; workerNumb < threadsCount; workerNumb++) {
              const startIndex = oneThreadPart * workerNumb;
              const endIndex = oneThreadPart * (workerNumb + 1);
              const worker = new Worker(__filename, {
                workerData: {
                  vector1: vector1.slice(startIndex, endIndex),
                  vector2: vector2.slice(startIndex, endIndex),
                  resultsBuffer,
                  workerNumb,
                },
              });
              workers.push(worker);
            }
            const parallelStart = new Date().getTime();
            return Promise.all(
              workers.map(
                worker =>
                  new Promise(res => {
                    worker.on('exit', () => res(results));
                  })
              )
            ).then(results => {
              const parallelTime = new Date().getTime() - parallelStart;
              const parallelRes = results[0].reduce((prv, curr) => prv + curr);

              console.log(`Seq result: ${sequentialResult}`);
              console.log(`Par result: ${parallelRes}`);
              console.log(`Seq time: ${sequentialTime}ms`);
              console.log(`Par time: ${parallelTime}ms\n`);
              const boostSpeedCoef = sequentialTime / parallelTime;
              return { value: [boostSpeedCoef, boostSpeedCoef / threadsCount] };
            });
          },
        };
      },
    };

    THREADS_COUNT_TESTS.forEach(threadsCount =>
      VECTOR_LENGTH_TESTS.forEach(vectorLength =>
        tests.units.push({ threadsCount, vectorLength })
      )
    );
    for await (let [boostSpeedCoef, efficiency] of tests) {
      console.log(`S = ${boostSpeedCoef.toFixed(3)}`);
      console.log(`E = ${efficiency.toFixed(3)}`);
      console.log('================\n');
    }
  };
  f();
} else {
  const { vector1, vector2, resultsBuffer, workerNumb } = threads.workerData;
  const results = new Int32Array(resultsBuffer);

  const product = scalarProduct(vector1, vector2);
  results[workerNumb] = product;
}


Вивід та висновки:














 Одразу можемо пересвідчитися у тому, що у кожному тесті результат виконання послідновного та паралельного алгоритмів однакові
Як бачимо, користь додаткових потоків починає бути помітна лише на 16 потоках. На 4 та 8 потоках витрачається більше ресурсів на їх створення та обслуговування, ніж вони дають коритсі. З ростом кількості тредів розрив буде все більшим і більшим, так наприклад при 64 потоках, розрив вже складає приблизно 400%: 









Однак за законом Амдала цей ріст не буде нескінченним. Також видно що при збільшенні кількості потоків зменшується різниця між часом обчислення даних різних розмірів. Наприклад при 256 потоках паралельна обробка даних, розміри яких відрізняються вдвічі практично однакова, у той час як послідовна обробка масивів відрізняєтсья приблизно у 2 рази: 


